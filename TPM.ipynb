{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJOQ6mjWhUSJ"
      },
      "outputs": [],
      "source": [
        "!pip install rapidfuzz\n",
        "# Solo es necesario si no las tienes ya\n",
        "!pip install kmodes plotly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKwIZbAHcUuQ"
      },
      "outputs": [],
      "source": [
        "# ‚Äî Manipulaci√≥n de datos ‚Äî\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ‚Äî C√°lculos de distancia y clustering jer√°rquico ‚Äî\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "\n",
        "# ‚Äî M√©tricas de validaci√≥n de clustering ‚Äî\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score\n",
        ")\n",
        "\n",
        "# ‚Äî Clustering ‚Äúusuales‚Äù en Python ‚Äî\n",
        "from sklearn.cluster import (\n",
        "    KMeans,\n",
        "    AgglomerativeClustering,\n",
        "    SpectralClustering\n",
        ")\n",
        "from kmodes.kprototypes import KPrototypes  # si usas clustering mixto\n",
        "\n",
        "# ‚Äî Reducci√≥n de dimensi√≥n y proyecciones ‚Äî\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ‚Äî Normalizaci√≥n y transformaciones ‚Äî\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "\n",
        "# ‚Äî Visualizaci√≥n ‚Äî\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFLI_GHaP__y"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo (aj√∫stala si tu entorno difiere)\n",
        "data = '/content/drive/MyDrive/proyecto_ingeneria/df.xlsx'\n",
        "\n",
        "# 1. Leer el Excel\n",
        "data= pd.read_excel(data)\n",
        "\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHe4Z3A4gGS6"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo (aj√∫stala si tu entorno difiere)\n",
        "classification_locations = pd.read_csv('/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv', sep=';')\n",
        "\n",
        "\n",
        "# 1. Leer el Excel\n",
        "\n",
        "\n",
        "classification_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imiWw-LKuq69"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import operator\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.metrics import pairwise_distances, silhouette_score, silhouette_samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBTOmhEdDNna"
      },
      "outputs": [],
      "source": [
        "#!pip install -U kaleido\n",
        "!pip install -U plotly\n",
        "!pip install kaleido==0.2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_elrGVSeBWhV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pickle as pick\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import pairwise_distances, silhouette_score, silhouette_samples\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "class DatabasePreparation:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "\n",
        "    def loadingDatabase(self, url):\n",
        "        self.data = pd.read_excel(url, engine=\"openpyxl\", dtype=str)\n",
        "        self.data = self.data[[\n",
        "            \"user\", \"memberID\", \"user_location\", \"date_review\",\n",
        "            \"nom\", \"reviewed_category\", \"reviewed_location\",\n",
        "            \"comment\", \"score\", \"country\", \"id\"\n",
        "        ]]\n",
        "        print(self.data.head())\n",
        "        print(self.data.info())\n",
        "        print(self.data.isnull().sum() * 100 / len(self.data))\n",
        "\n",
        "    def preprocessing(self):\n",
        "        self.data[\"date_review\"] = pd.to_datetime(self.data[\"date_review\"], errors=\"coerce\")\n",
        "        self.data = self.data.dropna(subset=[\"date_review\", \"memberID\", \"id\"])\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(self.data.head())\n",
        "        print(self.data.info())\n",
        "        print(self.data.isnull().sum() * 100 / len(self.data))\n",
        "\n",
        "    def filterTopLocations(self, seuil=20):\n",
        "        return self.data[\"id\"].value_counts().nlargest(seuil).index.tolist()\n",
        "\n",
        "class LocationsClassification:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.classification = None\n",
        "\n",
        "    def load(self):\n",
        "        self.classification = pd.read_csv(self.path, sep=\";\")\n",
        "        self.classification = self.classification[[\"id\", \"nom\", \"categorie\"]]\n",
        "        print(self.classification.head())\n",
        "        print(self.classification.info())\n",
        "\n",
        "    def check_match(self, top_ids):\n",
        "        classified_ids = set(self.classification[\"id\"].astype(str))\n",
        "        missing = set(map(str, top_ids)) - classified_ids\n",
        "        if not missing:\n",
        "            print(\"La diferencia entre la lista de monumentos clasificados y el top es nula\")\n",
        "        else:\n",
        "            raise ValueError(f\"IDs faltantes en clasificaci√≥n: {missing}\")\n",
        "\n",
        "class Seasonality:\n",
        "    def detect(self, date):\n",
        "        m, d = date.month, date.day\n",
        "        if (m == 12 and d >= 21) or (1 <= m <= 2) or (m == 3 and d < 20):\n",
        "            return \"Winter\"\n",
        "        elif (m == 3 and d >= 20) or (4 <= m <= 5) or (m == 6 and d < 21):\n",
        "            return \"Spring\"\n",
        "        elif (m == 6 and d >= 21) or (7 <= m <= 8) or (m == 9 and d < 22):\n",
        "            return \"Summer\"\n",
        "        else:\n",
        "            return \"Autumn\"\n",
        "\n",
        "class TripsList:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def create_trips(self, top_ids, threshold=15):\n",
        "        trips_dict = {}\n",
        "        data_top = self.data[self.data[\"id\"].isin(top_ids)].copy()\n",
        "        for user, group in data_top.groupby(\"memberID\"):\n",
        "            group = group.sort_values(\"date_review\")\n",
        "            user_trips = []\n",
        "            curr_trip = []\n",
        "            last_date = None\n",
        "            for _, row in group.iterrows():\n",
        "                if last_date is None or (row[\"date_review\"] - last_date).days <= threshold:\n",
        "                    curr_trip.append((row[\"date_review\"], row[\"id\"]))\n",
        "                else:\n",
        "                    if len(curr_trip) > 1:\n",
        "                        user_trips.append(curr_trip)\n",
        "                    curr_trip = [(row[\"date_review\"], row[\"id\"])]\n",
        "                last_date = row[\"date_review\"]\n",
        "            if len(curr_trip) > 1:\n",
        "                user_trips.append(curr_trip)\n",
        "            if user_trips:\n",
        "                trips_dict[user] = user_trips\n",
        "        return trips_dict\n",
        "\n",
        "def construir_list_trips(trips_dict):\n",
        "    seasonality = Seasonality()\n",
        "    list_trips = {}\n",
        "    trip_id = 0\n",
        "    for user, trips in trips_dict.items():\n",
        "        for trip in trips:\n",
        "            locs = [t[1] for t in trip]\n",
        "            dur = (trip[-1][0] - trip[0][0]).days\n",
        "            seas = seasonality.detect(trip[0][0])\n",
        "            list_trips[trip_id] = (locs, seas, dur, user)\n",
        "            trip_id += 1\n",
        "    print(f\"\\nIl y a {len(list_trips)} trips dans la base de donn√©es\")\n",
        "    return list_trips\n",
        "\n",
        "def construir_base_numerica(list_trips):\n",
        "    all_locations = sorted(set(loc for v in list_trips.values() for loc in v[0]))\n",
        "    loc_idx = {loc: i for i, loc in enumerate(all_locations)}\n",
        "    rows = []\n",
        "    for locs, season, dur, _ in list_trips.values():\n",
        "        vec = np.zeros(len(all_locations))\n",
        "        for loc in locs:\n",
        "            vec[loc_idx[loc]] += 1\n",
        "        season_code = hash(season) % 1000\n",
        "        row = np.concatenate([vec, [season_code, dur]])\n",
        "        rows.append(row)\n",
        "    df = pd.DataFrame(rows)\n",
        "    print(\"\\n--- database_num.head() ---\\n\", df.head())\n",
        "    print(\"\\n--- database_num.info() ---\\n\", df.info())\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    path_data = \"/content/drive/MyDrive/proyecto_ingeneria/df.xlsx\"\n",
        "    path_class = \"/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv\"\n",
        "    region = \"america\"\n",
        "    a, b = 0.8, 0.2\n",
        "    seuil_top = 20\n",
        "    threshold_trip = 7\n",
        "    output_dir = Path(f\"res/{region}/todos_los_anios\")\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    db = DatabasePreparation()\n",
        "    db.loadingDatabase(path_data)\n",
        "    db.preprocessing()\n",
        "    data = db.data\n",
        "\n",
        "    cl = LocationsClassification(path_class)\n",
        "    cl.load()\n",
        "    top_ids = db.filterTopLocations(seuil_top)\n",
        "    cl.check_match(top_ids)\n",
        "\n",
        "    trips = TripsList(data)\n",
        "    trips_dict = trips.create_trips(top_ids, threshold_trip)\n",
        "    list_trips = construir_list_trips(trips_dict)\n",
        "    database_num = construir_base_numerica(list_trips)\n",
        "\n",
        "    content_matrix = pairwise_distances(database_num.iloc[:, :-2])\n",
        "    context_matrix = pairwise_distances(database_num.iloc[:, -2:])\n",
        "    combined = normalize(a * content_matrix + b * context_matrix, axis=1, norm=\"l1\")\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}.pkl\", \"wb\") as f:\n",
        "        pick.dump(combined, f)\n",
        "\n",
        "    # ======== Silhouette test autom√°tico para k = 2 to 100 =========\n",
        "    print(\"üìà Generando gr√°fico de silhouette‚Ä¶\")\n",
        "    silhouette_scores = []\n",
        "    k_range = range(2, 101)\n",
        "    for k in k_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0).fit(combined)\n",
        "        score = silhouette_score(combined, kmeans.labels_)\n",
        "        silhouette_scores.append(score)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(k_range, silhouette_scores, marker='o', linestyle='-')\n",
        "    plt.xlabel(\"k\")\n",
        "    plt.ylabel(\"silhouette\")\n",
        "    plt.title(\"Silhouette Score vs k\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(output_dir / f\"silhouette_k_comparison.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # ======== Preguntar valor final de k ========\n",
        "    while True:\n",
        "        try:\n",
        "            k = int(input(\"Quel est la valeur de k ? \"))\n",
        "            if k > 1:\n",
        "                break\n",
        "        except:\n",
        "            print(\"Entrada inv√°lida.\")\n",
        "\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0).fit(combined)\n",
        "    labels = kmeans.labels_\n",
        "    silhouette_avg = silhouette_score(combined, labels)\n",
        "    silhouette_vals = silhouette_samples(combined, labels)\n",
        "\n",
        "    # Silhouette final\n",
        "    fig_sil = px.bar(\n",
        "        x=np.arange(len(silhouette_vals)),\n",
        "        y=silhouette_vals,\n",
        "        color=labels.astype(str),\n",
        "        title=f\"Silhouette plot (a={a}, b={b})\"\n",
        "    )\n",
        "    fig_sil.write_html(output_dir / f\"silhouette_{a:.1f}_{b:.1f}.html\")\n",
        "    fig_sil.write_image(output_dir / f\"silhouette_{a:.1f}_{b:.1f}.png\")\n",
        "\n",
        "    # Proyecci√≥n MDS\n",
        "    mds = MDS(random_state=0, dissimilarity='precomputed')\n",
        "    last_combined = combined + combined.T - np.diag(np.diag(combined))\n",
        "    projection = mds.fit_transform(last_combined)\n",
        "\n",
        "    fig_proj = px.scatter(x=projection[:, 0], y=projection[:, 1],\n",
        "                          color=labels.astype(str),\n",
        "                          title=f\"Proyecci√≥n (a={a:.1f}, b={b:.1f})\")\n",
        "    fig_proj.write_html(output_dir / f\"{a:.1f}_{b:.1f}_projection.html\")\n",
        "\n",
        "    df_clusters = pd.DataFrame({\"trip_id\": range(len(labels)), \"cluster\": labels})\n",
        "    df_clusters.to_csv(output_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\", index=False)\n",
        "    df_clusters.to_excel(output_dir / f\"{a:.1f}_{b:.1f}_clusters.xlsx\", index=False)\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}_clusters.pkl\", \"wb\") as f:\n",
        "        pick.dump(labels, f)\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}_summary.pkl\", \"wb\") as f:\n",
        "        pick.dump({\n",
        "            \"a\": a, \"b\": b, \"k\": k, \"silhouette\": silhouette_avg\n",
        "        }, f)\n",
        "\n",
        "    database_num.to_csv(output_dir / \"base_numerica.csv\", index=False)\n",
        "    with open(output_dir / \"list_trips.pkl\", \"wb\") as f:\n",
        "        pick.dump(list_trips, f)\n",
        "\n",
        "    print(f\"\\n‚úÖ Silhouette final: {silhouette_avg:.4f}\")\n",
        "    print(\"üéâ TODOS LOS RESULTADOS GUARDADOS.\")\n",
        "    print(\"DONE ‚úÖ\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOoYD5TlPo0X"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def generar_visualizacion_global(region=\"america\", a=0.8, b=0.2):\n",
        "    base_path = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"üìä Procesando visualizaci√≥n global para todos los a√±os‚Ä¶\")\n",
        "\n",
        "        df_trips = pd.read_pickle(base_path / \"list_trips.pkl\")\n",
        "        df_clusters = pd.read_csv(base_path / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "        classification = pd.read_csv(\"/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv\", sep=\";\")\n",
        "\n",
        "        df_trips_df = pd.DataFrame.from_dict(\n",
        "            df_trips, orient=\"index\",\n",
        "            columns=[\"locations\", \"season\", \"duration\", \"user\"]\n",
        "        ).reset_index().rename(columns={'index': 'trip_id'})\n",
        "\n",
        "        df_trips_df[\"cluster\"] = df_clusters[\"cluster\"]\n",
        "\n",
        "        # ========== SEASONALITY ========== (sin cambios)\n",
        "# ========== SEASONALITY ========== (corregido)\n",
        "        season_order = [\"Summer\", \"Autumn\", \"Spring\", \"Winter\"]\n",
        "        pivot_season = pd.crosstab(df_trips_df[\"cluster\"], df_trips_df[\"season\"], normalize='index') * 100\n",
        "\n",
        "# Asegurar que todas las estaciones est√©n como columnas (aunque sean 0%)\n",
        "        for season in season_order:\n",
        "          if season not in pivot_season.columns:\n",
        "            pivot_season[season] = 0\n",
        "\n",
        "        pivot_season = pivot_season[season_order]\n",
        "\n",
        "        cluster_order = sorted(df_trips_df[\"cluster\"].unique())  # orden consistente de clusters\n",
        "        pivot_season = pivot_season.loc[cluster_order]  # aplica orden\n",
        "\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 3))\n",
        "        pivot_season.plot(kind='bar', stacked=True, ax=ax, colormap=\"tab20c\")\n",
        "        ax.set_ylabel(\"Percentage\")\n",
        "        ax.set_xlabel(\"Cluster\")\n",
        "        ax.legend(title=\"Season\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"seasonality_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # ========== CATEGORIES ========== (solo este bloque est√° modificado)\n",
        "        classification_categ = classification.copy()\n",
        "\n",
        "        def normalizar_categoria(cat):\n",
        "            cat = str(cat).lower().strip()\n",
        "            if \"shops/restaurants and bars/gastronomy\" in cat:\n",
        "                return \"Shops/restaurants and bars/gastronomy\"\n",
        "            elif \"urbanism\" in cat:\n",
        "                return \"Urbanism\"\n",
        "            else:\n",
        "                return cat.title()\n",
        "\n",
        "        classification_categ[\"categorie\"] = classification_categ[\"categorie\"].apply(normalizar_categoria)\n",
        "        id_to_cat = dict(zip(classification_categ[\"id\"].astype(str), classification_categ[\"categorie\"]))\n",
        "\n",
        "        cluster_cat_counts = defaultdict(lambda: defaultdict(int))\n",
        "        for trip_id, (locs, _, _, _) in df_trips.items():\n",
        "            clus = df_clusters.loc[trip_id, \"cluster\"]\n",
        "            for loc in locs:\n",
        "                cat = id_to_cat.get(str(loc), \"Unknown\")\n",
        "                cluster_cat_counts[clus][cat] += 1\n",
        "\n",
        "        cat_df = pd.DataFrame(cluster_cat_counts).fillna(0).sort_index(axis=1).sort_index()\n",
        "        cat_pct = cat_df.div(cat_df.sum(axis=0), axis=1) * 100\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(11, 4))\n",
        "        cat_pct.T.plot(kind='bar', stacked=True, ax=ax, colormap=\"tab20\")\n",
        "        ax.set_ylabel(\"Percentage\")\n",
        "        ax.set_xlabel(\"Cluster\")\n",
        "        ax.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"categories_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # ========== RESUMEN ==========\n",
        "        resumen = df_trips_df.groupby(\"cluster\").agg({\n",
        "            \"duration\": [\"mean\", \"std\", \"count\"],\n",
        "            \"user\": \"count\"\n",
        "        })\n",
        "        resumen.columns = [\"duration_mean\", \"duration_std\", \"n_stays\", \"n_reviews\"]\n",
        "        resumen[\"reviews_per_stay\"] = resumen[\"n_reviews\"] / resumen[\"n_stays\"]\n",
        "\n",
        "        resumen.loc[\"Dataset\"] = [\n",
        "            df_trips_df[\"duration\"].mean(),\n",
        "            df_trips_df[\"duration\"].std(),\n",
        "            df_trips_df.shape[0],\n",
        "            df_trips_df[\"user\"].count(),\n",
        "            df_trips_df[\"user\"].count() / df_trips_df.shape[0]\n",
        "        ]\n",
        "\n",
        "        def fmt(mean, std):\n",
        "            return f\"{mean:.3g} ¬± {std:.2g}\" if pd.notnull(std) else f\"{mean:.3g} ¬± 0\"\n",
        "\n",
        "        table_fmt = pd.DataFrame({\n",
        "            \"Average duration + std\": resumen.apply(lambda x: fmt(x[\"duration_mean\"], x[\"duration_std\"]), axis=1),\n",
        "            \"No. of stays + %\": resumen[\"n_stays\"].apply(lambda x: f\"{int(x)}\") + \" ¬± \" +\n",
        "                                 resumen[\"n_stays\"].div(resumen.loc[\"Dataset\", \"n_stays\"]).mul(100).round(1).astype(str),\n",
        "            \"Reviews per stay means + Std\": resumen.apply(lambda x: fmt(x[\"reviews_per_stay\"], 0), axis=1)\n",
        "        })\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 4))\n",
        "        ax.axis('off')\n",
        "        tbl = ax.table(cellText=table_fmt.values,\n",
        "                       colLabels=table_fmt.columns,\n",
        "                       rowLabels=table_fmt.index,\n",
        "                       loc='center')\n",
        "        tbl.auto_set_font_size(False)\n",
        "        tbl.set_fontsize(9)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"resumen_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        print(\"‚úÖ Visualizaciones globales generadas correctamente.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error en visualizaci√≥n global: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phV3aHfAPp2P"
      },
      "outputs": [],
      "source": [
        "generar_visualizacion_global()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46uN4-oQibW"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O-d6NS4QhFi"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def visualizar_clusters_umap(region=\"america\", a=0.8, b=0.2):\n",
        "    input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"üìä Generando proyecci√≥n UMAP‚Ä¶\")\n",
        "        database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "        df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "        reducer = umap.UMAP(random_state=42)\n",
        "        projection = reducer.fit_transform(database_num)\n",
        "\n",
        "        df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "        df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", s=10, alpha=0.7)\n",
        "        plt.title(f\"Visualizaci√≥n de clusters con UMAP (a={a}, b={b})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"umap_clusters_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"‚úÖ Gr√°fico de clusters generado y guardado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error generando gr√°fico UMAP: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izRxrKeXQn3h"
      },
      "outputs": [],
      "source": [
        "visualizar_clusters_umap()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOhAg4F9WvOi"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "!python -m spacy download es_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MCklM7HgWhc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Leer datos\n",
        "region = \"america\"\n",
        "a, b = 0.8, 0.2\n",
        "input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "\n",
        "# Cargar proyecci√≥n UMAP y clusters\n",
        "database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "# Reducir dimensiones con UMAP\n",
        "import umap\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "projection = reducer.fit_transform(database_num)\n",
        "\n",
        "# Crear DataFrame para an√°lisis\n",
        "df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "# Agrupar clusters usando KMeans sobre la proyecci√≥n UMAP\n",
        "kmeans_vis = KMeans(n_clusters=4, random_state=42)\n",
        "df_plot[\"group\"] = kmeans_vis.fit_predict(df_plot[[\"x\", \"y\"]])\n",
        "\n",
        "# Listar clusters por grupo\n",
        "group_to_clusters = df_plot.groupby(\"group\")[\"cluster\"].unique().to_dict()\n",
        "group_to_clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeoCardKn3aX"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def visualizar_clusters_umap(region=\"america\", a=0.8, b=0.2):\n",
        "    input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"üìä Generando proyecci√≥n UMAP‚Ä¶\")\n",
        "        database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "        df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "        reducer = umap.UMAP(random_state=42)\n",
        "        projection = reducer.fit_transform(database_num)\n",
        "\n",
        "        df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "        df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "        plt.figure(figsize=(12, 8))  # gr√°fico m√°s grande\n",
        "        sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", s=10, alpha=0.7)\n",
        "\n",
        "        # Ajustes para expandir visualmente el √°rea\n",
        "        margin = 2\n",
        "        plt.xlim(df_plot[\"x\"].min() - margin, df_plot[\"x\"].max() + margin)\n",
        "        plt.ylim(df_plot[\"y\"].min() - margin, df_plot[\"y\"].max() + margin)\n",
        "\n",
        "        plt.title(f\"Visualizaci√≥n de clusters con UMAP (a={a}, b={b})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"umap_clusters_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"‚úÖ Gr√°fico de clusters generado y guardado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error generando gr√°fico UMAP: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLOuuHran4wQ"
      },
      "outputs": [],
      "source": [
        "visualizar_clusters_umap()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw1rlCQA3W05"
      },
      "outputs": [],
      "source": [
        "# Reimportar librer√≠as tras reinicio del entorno\n",
        "import pandas as pd\n",
        "import pickle as pick\n",
        "from pathlib import Path\n",
        "\n",
        "# Cargar paths\n",
        "region = \"america\"\n",
        "a, b = 0.8, 0.2\n",
        "base_path = Path(\"res\") / region / \"todos_los_anios\"\n",
        "\n",
        "# Cargar archivos necesarios nuevamente\n",
        "with open(base_path / \"list_trips.pkl\", \"rb\") as f:\n",
        "    list_trips = pick.load(f)\n",
        "\n",
        "df_clusters = pd.read_csv(base_path / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "df_original = pd.read_excel(\"/content/drive/MyDrive/proyecto_ingeneria/df.xlsx\", engine=\"openpyxl\", dtype=str)\n",
        "df_original[\"date_review\"] = pd.to_datetime(df_original[\"date_review\"], errors=\"coerce\")\n",
        "\n",
        "# Crear DataFrame de estancias\n",
        "records = []\n",
        "for trip_id, (locations, season, duration, user) in list_trips.items():\n",
        "    user_reviews = df_original[(df_original[\"memberID\"] == user) & (df_original[\"id\"].isin(locations))]\n",
        "    for _, row in user_reviews.iterrows():\n",
        "        records.append({\n",
        "            \"trip_id\": trip_id,\n",
        "            \"memberID\": row[\"memberID\"],\n",
        "            \"country\": row[\"country\"],\n",
        "            \"reviewed_location\": row[\"reviewed_location\"],\n",
        "            \"id\": row[\"id\"],\n",
        "            \"cluster\": df_clusters.loc[trip_id, \"cluster\"]\n",
        "        })\n",
        "\n",
        "df_stays = pd.DataFrame(records)\n",
        "\n",
        "# Guardar Excel\n",
        "output_path = base_path / f\"estancias_clusterizadas.xlsx\"\n",
        "df_stays.to_excel(output_path, index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

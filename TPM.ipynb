{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJOQ6mjWhUSJ"
      },
      "outputs": [],
      "source": [
        "!pip install rapidfuzz\n",
        "# Solo es necesario si no las tienes ya\n",
        "!pip install kmodes plotly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKwIZbAHcUuQ"
      },
      "outputs": [],
      "source": [
        "# — Manipulación de datos —\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# — Cálculos de distancia y clustering jerárquico —\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "\n",
        "# — Métricas de validación de clustering —\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score\n",
        ")\n",
        "\n",
        "# — Clustering “usuales” en Python —\n",
        "from sklearn.cluster import (\n",
        "    KMeans,\n",
        "    AgglomerativeClustering,\n",
        "    SpectralClustering\n",
        ")\n",
        "from kmodes.kprototypes import KPrototypes  # si usas clustering mixto\n",
        "\n",
        "# — Reducción de dimensión y proyecciones —\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# — Normalización y transformaciones —\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "\n",
        "# — Visualización —\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFLI_GHaP__y"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo (ajústala si tu entorno difiere)\n",
        "data = '/content/drive/MyDrive/proyecto_ingeneria/df.xlsx'\n",
        "\n",
        "# 1. Leer el Excel\n",
        "data= pd.read_excel(data)\n",
        "\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHe4Z3A4gGS6"
      },
      "outputs": [],
      "source": [
        "# Ruta al archivo (ajústala si tu entorno difiere)\n",
        "classification_locations = pd.read_csv('/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv', sep=';')\n",
        "\n",
        "\n",
        "# 1. Leer el Excel\n",
        "\n",
        "\n",
        "classification_locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imiWw-LKuq69"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import operator\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.metrics import pairwise_distances, silhouette_score, silhouette_samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBTOmhEdDNna"
      },
      "outputs": [],
      "source": [
        "#!pip install -U kaleido\n",
        "!pip install -U plotly\n",
        "!pip install kaleido==0.2.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_elrGVSeBWhV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pickle as pick\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import pairwise_distances, silhouette_score, silhouette_samples\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "class DatabasePreparation:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "\n",
        "    def loadingDatabase(self, url):\n",
        "        self.data = pd.read_excel(url, engine=\"openpyxl\", dtype=str)\n",
        "        self.data = self.data[[\n",
        "            \"user\", \"memberID\", \"user_location\", \"date_review\",\n",
        "            \"nom\", \"reviewed_category\", \"reviewed_location\",\n",
        "            \"comment\", \"score\", \"country\", \"id\"\n",
        "        ]]\n",
        "        print(self.data.head())\n",
        "        print(self.data.info())\n",
        "        print(self.data.isnull().sum() * 100 / len(self.data))\n",
        "\n",
        "    def preprocessing(self):\n",
        "        self.data[\"date_review\"] = pd.to_datetime(self.data[\"date_review\"], errors=\"coerce\")\n",
        "        self.data = self.data.dropna(subset=[\"date_review\", \"memberID\", \"id\"])\n",
        "        self.data = self.data.reset_index(drop=True)\n",
        "        print(self.data.head())\n",
        "        print(self.data.info())\n",
        "        print(self.data.isnull().sum() * 100 / len(self.data))\n",
        "\n",
        "    def filterTopLocations(self, seuil=20):\n",
        "        return self.data[\"id\"].value_counts().nlargest(seuil).index.tolist()\n",
        "\n",
        "class LocationsClassification:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.classification = None\n",
        "\n",
        "    def load(self):\n",
        "        self.classification = pd.read_csv(self.path, sep=\";\")\n",
        "        self.classification = self.classification[[\"id\", \"nom\", \"categorie\"]]\n",
        "        print(self.classification.head())\n",
        "        print(self.classification.info())\n",
        "\n",
        "    def check_match(self, top_ids):\n",
        "        classified_ids = set(self.classification[\"id\"].astype(str))\n",
        "        missing = set(map(str, top_ids)) - classified_ids\n",
        "        if not missing:\n",
        "            print(\"La diferencia entre la lista de monumentos clasificados y el top es nula\")\n",
        "        else:\n",
        "            raise ValueError(f\"IDs faltantes en clasificación: {missing}\")\n",
        "\n",
        "class Seasonality:\n",
        "    def detect(self, date):\n",
        "        m, d = date.month, date.day\n",
        "        if (m == 12 and d >= 21) or (1 <= m <= 2) or (m == 3 and d < 20):\n",
        "            return \"Winter\"\n",
        "        elif (m == 3 and d >= 20) or (4 <= m <= 5) or (m == 6 and d < 21):\n",
        "            return \"Spring\"\n",
        "        elif (m == 6 and d >= 21) or (7 <= m <= 8) or (m == 9 and d < 22):\n",
        "            return \"Summer\"\n",
        "        else:\n",
        "            return \"Autumn\"\n",
        "\n",
        "class TripsList:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def create_trips(self, top_ids, threshold=15):\n",
        "        trips_dict = {}\n",
        "        data_top = self.data[self.data[\"id\"].isin(top_ids)].copy()\n",
        "        for user, group in data_top.groupby(\"memberID\"):\n",
        "            group = group.sort_values(\"date_review\")\n",
        "            user_trips = []\n",
        "            curr_trip = []\n",
        "            last_date = None\n",
        "            for _, row in group.iterrows():\n",
        "                if last_date is None or (row[\"date_review\"] - last_date).days <= threshold:\n",
        "                    curr_trip.append((row[\"date_review\"], row[\"id\"]))\n",
        "                else:\n",
        "                    if len(curr_trip) > 1:\n",
        "                        user_trips.append(curr_trip)\n",
        "                    curr_trip = [(row[\"date_review\"], row[\"id\"])]\n",
        "                last_date = row[\"date_review\"]\n",
        "            if len(curr_trip) > 1:\n",
        "                user_trips.append(curr_trip)\n",
        "            if user_trips:\n",
        "                trips_dict[user] = user_trips\n",
        "        return trips_dict\n",
        "\n",
        "def construir_list_trips(trips_dict):\n",
        "    seasonality = Seasonality()\n",
        "    list_trips = {}\n",
        "    trip_id = 0\n",
        "    for user, trips in trips_dict.items():\n",
        "        for trip in trips:\n",
        "            locs = [t[1] for t in trip]\n",
        "            dur = (trip[-1][0] - trip[0][0]).days\n",
        "            seas = seasonality.detect(trip[0][0])\n",
        "            list_trips[trip_id] = (locs, seas, dur, user)\n",
        "            trip_id += 1\n",
        "    print(f\"\\nIl y a {len(list_trips)} trips dans la base de données\")\n",
        "    return list_trips\n",
        "\n",
        "def construir_base_numerica(list_trips):\n",
        "    all_locations = sorted(set(loc for v in list_trips.values() for loc in v[0]))\n",
        "    loc_idx = {loc: i for i, loc in enumerate(all_locations)}\n",
        "    rows = []\n",
        "    for locs, season, dur, _ in list_trips.values():\n",
        "        vec = np.zeros(len(all_locations))\n",
        "        for loc in locs:\n",
        "            vec[loc_idx[loc]] += 1\n",
        "        season_code = hash(season) % 1000\n",
        "        row = np.concatenate([vec, [season_code, dur]])\n",
        "        rows.append(row)\n",
        "    df = pd.DataFrame(rows)\n",
        "    print(\"\\n--- database_num.head() ---\\n\", df.head())\n",
        "    print(\"\\n--- database_num.info() ---\\n\", df.info())\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    path_data = \"/content/drive/MyDrive/proyecto_ingeneria/df.xlsx\"\n",
        "    path_class = \"/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv\"\n",
        "    region = \"america\"\n",
        "    a, b = 0.8, 0.2\n",
        "    seuil_top = 20\n",
        "    threshold_trip = 7\n",
        "    output_dir = Path(f\"res/{region}/todos_los_anios\")\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    db = DatabasePreparation()\n",
        "    db.loadingDatabase(path_data)\n",
        "    db.preprocessing()\n",
        "    data = db.data\n",
        "\n",
        "    cl = LocationsClassification(path_class)\n",
        "    cl.load()\n",
        "    top_ids = db.filterTopLocations(seuil_top)\n",
        "    cl.check_match(top_ids)\n",
        "\n",
        "    trips = TripsList(data)\n",
        "    trips_dict = trips.create_trips(top_ids, threshold_trip)\n",
        "    list_trips = construir_list_trips(trips_dict)\n",
        "    database_num = construir_base_numerica(list_trips)\n",
        "\n",
        "    content_matrix = pairwise_distances(database_num.iloc[:, :-2])\n",
        "    context_matrix = pairwise_distances(database_num.iloc[:, -2:])\n",
        "    combined = normalize(a * content_matrix + b * context_matrix, axis=1, norm=\"l1\")\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}.pkl\", \"wb\") as f:\n",
        "        pick.dump(combined, f)\n",
        "\n",
        "    # ======== Silhouette test automático para k = 2 to 100 =========\n",
        "    print(\"📈 Generando gráfico de silhouette…\")\n",
        "    silhouette_scores = []\n",
        "    k_range = range(2, 101)\n",
        "    for k in k_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0).fit(combined)\n",
        "        score = silhouette_score(combined, kmeans.labels_)\n",
        "        silhouette_scores.append(score)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(k_range, silhouette_scores, marker='o', linestyle='-')\n",
        "    plt.xlabel(\"k\")\n",
        "    plt.ylabel(\"silhouette\")\n",
        "    plt.title(\"Silhouette Score vs k\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(output_dir / f\"silhouette_k_comparison.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # ======== Preguntar valor final de k ========\n",
        "    while True:\n",
        "        try:\n",
        "            k = int(input(\"Quel est la valeur de k ? \"))\n",
        "            if k > 1:\n",
        "                break\n",
        "        except:\n",
        "            print(\"Entrada inválida.\")\n",
        "\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0).fit(combined)\n",
        "    labels = kmeans.labels_\n",
        "    silhouette_avg = silhouette_score(combined, labels)\n",
        "    silhouette_vals = silhouette_samples(combined, labels)\n",
        "\n",
        "    # Silhouette final\n",
        "    fig_sil = px.bar(\n",
        "        x=np.arange(len(silhouette_vals)),\n",
        "        y=silhouette_vals,\n",
        "        color=labels.astype(str),\n",
        "        title=f\"Silhouette plot (a={a}, b={b})\"\n",
        "    )\n",
        "    fig_sil.write_html(output_dir / f\"silhouette_{a:.1f}_{b:.1f}.html\")\n",
        "    fig_sil.write_image(output_dir / f\"silhouette_{a:.1f}_{b:.1f}.png\")\n",
        "\n",
        "    # Proyección MDS\n",
        "    mds = MDS(random_state=0, dissimilarity='precomputed')\n",
        "    last_combined = combined + combined.T - np.diag(np.diag(combined))\n",
        "    projection = mds.fit_transform(last_combined)\n",
        "\n",
        "    fig_proj = px.scatter(x=projection[:, 0], y=projection[:, 1],\n",
        "                          color=labels.astype(str),\n",
        "                          title=f\"Proyección (a={a:.1f}, b={b:.1f})\")\n",
        "    fig_proj.write_html(output_dir / f\"{a:.1f}_{b:.1f}_projection.html\")\n",
        "\n",
        "    df_clusters = pd.DataFrame({\"trip_id\": range(len(labels)), \"cluster\": labels})\n",
        "    df_clusters.to_csv(output_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\", index=False)\n",
        "    df_clusters.to_excel(output_dir / f\"{a:.1f}_{b:.1f}_clusters.xlsx\", index=False)\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}_clusters.pkl\", \"wb\") as f:\n",
        "        pick.dump(labels, f)\n",
        "\n",
        "    with open(output_dir / f\"{a:.1f}_{b:.1f}_summary.pkl\", \"wb\") as f:\n",
        "        pick.dump({\n",
        "            \"a\": a, \"b\": b, \"k\": k, \"silhouette\": silhouette_avg\n",
        "        }, f)\n",
        "\n",
        "    database_num.to_csv(output_dir / \"base_numerica.csv\", index=False)\n",
        "    with open(output_dir / \"list_trips.pkl\", \"wb\") as f:\n",
        "        pick.dump(list_trips, f)\n",
        "\n",
        "    print(f\"\\n✅ Silhouette final: {silhouette_avg:.4f}\")\n",
        "    print(\"🎉 TODOS LOS RESULTADOS GUARDADOS.\")\n",
        "    print(\"DONE ✅\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOoYD5TlPo0X"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def generar_visualizacion_global(region=\"america\", a=0.8, b=0.2):\n",
        "    base_path = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"📊 Procesando visualización global para todos los años…\")\n",
        "\n",
        "        df_trips = pd.read_pickle(base_path / \"list_trips.pkl\")\n",
        "        df_clusters = pd.read_csv(base_path / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "        classification = pd.read_csv(\"/content/drive/MyDrive/proyecto_ingeneria/Classification_locations.csv\", sep=\";\")\n",
        "\n",
        "        df_trips_df = pd.DataFrame.from_dict(\n",
        "            df_trips, orient=\"index\",\n",
        "            columns=[\"locations\", \"season\", \"duration\", \"user\"]\n",
        "        ).reset_index().rename(columns={'index': 'trip_id'})\n",
        "\n",
        "        df_trips_df[\"cluster\"] = df_clusters[\"cluster\"]\n",
        "\n",
        "        # ========== SEASONALITY ========== (sin cambios)\n",
        "# ========== SEASONALITY ========== (corregido)\n",
        "        season_order = [\"Summer\", \"Autumn\", \"Spring\", \"Winter\"]\n",
        "        pivot_season = pd.crosstab(df_trips_df[\"cluster\"], df_trips_df[\"season\"], normalize='index') * 100\n",
        "\n",
        "# Asegurar que todas las estaciones estén como columnas (aunque sean 0%)\n",
        "        for season in season_order:\n",
        "          if season not in pivot_season.columns:\n",
        "            pivot_season[season] = 0\n",
        "\n",
        "        pivot_season = pivot_season[season_order]\n",
        "\n",
        "        cluster_order = sorted(df_trips_df[\"cluster\"].unique())  # orden consistente de clusters\n",
        "        pivot_season = pivot_season.loc[cluster_order]  # aplica orden\n",
        "\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 3))\n",
        "        pivot_season.plot(kind='bar', stacked=True, ax=ax, colormap=\"tab20c\")\n",
        "        ax.set_ylabel(\"Percentage\")\n",
        "        ax.set_xlabel(\"Cluster\")\n",
        "        ax.legend(title=\"Season\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"seasonality_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # ========== CATEGORIES ========== (solo este bloque está modificado)\n",
        "        classification_categ = classification.copy()\n",
        "\n",
        "        def normalizar_categoria(cat):\n",
        "            cat = str(cat).lower().strip()\n",
        "            if \"shops/restaurants and bars/gastronomy\" in cat:\n",
        "                return \"Shops/restaurants and bars/gastronomy\"\n",
        "            elif \"urbanism\" in cat:\n",
        "                return \"Urbanism\"\n",
        "            else:\n",
        "                return cat.title()\n",
        "\n",
        "        classification_categ[\"categorie\"] = classification_categ[\"categorie\"].apply(normalizar_categoria)\n",
        "        id_to_cat = dict(zip(classification_categ[\"id\"].astype(str), classification_categ[\"categorie\"]))\n",
        "\n",
        "        cluster_cat_counts = defaultdict(lambda: defaultdict(int))\n",
        "        for trip_id, (locs, _, _, _) in df_trips.items():\n",
        "            clus = df_clusters.loc[trip_id, \"cluster\"]\n",
        "            for loc in locs:\n",
        "                cat = id_to_cat.get(str(loc), \"Unknown\")\n",
        "                cluster_cat_counts[clus][cat] += 1\n",
        "\n",
        "        cat_df = pd.DataFrame(cluster_cat_counts).fillna(0).sort_index(axis=1).sort_index()\n",
        "        cat_pct = cat_df.div(cat_df.sum(axis=0), axis=1) * 100\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(11, 4))\n",
        "        cat_pct.T.plot(kind='bar', stacked=True, ax=ax, colormap=\"tab20\")\n",
        "        ax.set_ylabel(\"Percentage\")\n",
        "        ax.set_xlabel(\"Cluster\")\n",
        "        ax.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"categories_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # ========== RESUMEN ==========\n",
        "        resumen = df_trips_df.groupby(\"cluster\").agg({\n",
        "            \"duration\": [\"mean\", \"std\", \"count\"],\n",
        "            \"user\": \"count\"\n",
        "        })\n",
        "        resumen.columns = [\"duration_mean\", \"duration_std\", \"n_stays\", \"n_reviews\"]\n",
        "        resumen[\"reviews_per_stay\"] = resumen[\"n_reviews\"] / resumen[\"n_stays\"]\n",
        "\n",
        "        resumen.loc[\"Dataset\"] = [\n",
        "            df_trips_df[\"duration\"].mean(),\n",
        "            df_trips_df[\"duration\"].std(),\n",
        "            df_trips_df.shape[0],\n",
        "            df_trips_df[\"user\"].count(),\n",
        "            df_trips_df[\"user\"].count() / df_trips_df.shape[0]\n",
        "        ]\n",
        "\n",
        "        def fmt(mean, std):\n",
        "            return f\"{mean:.3g} ± {std:.2g}\" if pd.notnull(std) else f\"{mean:.3g} ± 0\"\n",
        "\n",
        "        table_fmt = pd.DataFrame({\n",
        "            \"Average duration + std\": resumen.apply(lambda x: fmt(x[\"duration_mean\"], x[\"duration_std\"]), axis=1),\n",
        "            \"No. of stays + %\": resumen[\"n_stays\"].apply(lambda x: f\"{int(x)}\") + \" ± \" +\n",
        "                                 resumen[\"n_stays\"].div(resumen.loc[\"Dataset\", \"n_stays\"]).mul(100).round(1).astype(str),\n",
        "            \"Reviews per stay means + Std\": resumen.apply(lambda x: fmt(x[\"reviews_per_stay\"], 0), axis=1)\n",
        "        })\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 4))\n",
        "        ax.axis('off')\n",
        "        tbl = ax.table(cellText=table_fmt.values,\n",
        "                       colLabels=table_fmt.columns,\n",
        "                       rowLabels=table_fmt.index,\n",
        "                       loc='center')\n",
        "        tbl.auto_set_font_size(False)\n",
        "        tbl.set_fontsize(9)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"resumen_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        print(\"✅ Visualizaciones globales generadas correctamente.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error en visualización global: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phV3aHfAPp2P"
      },
      "outputs": [],
      "source": [
        "generar_visualizacion_global()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l46uN4-oQibW"
      },
      "outputs": [],
      "source": [
        "!pip install umap-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O-d6NS4QhFi"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def visualizar_clusters_umap(region=\"america\", a=0.8, b=0.2):\n",
        "    input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"📊 Generando proyección UMAP…\")\n",
        "        database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "        df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "        reducer = umap.UMAP(random_state=42)\n",
        "        projection = reducer.fit_transform(database_num)\n",
        "\n",
        "        df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "        df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", s=10, alpha=0.7)\n",
        "        plt.title(f\"Visualización de clusters con UMAP (a={a}, b={b})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"umap_clusters_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✅ Gráfico de clusters generado y guardado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error generando gráfico UMAP: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izRxrKeXQn3h"
      },
      "outputs": [],
      "source": [
        "visualizar_clusters_umap()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOhAg4F9WvOi"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "!python -m spacy download es_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MCklM7HgWhc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Leer datos\n",
        "region = \"america\"\n",
        "a, b = 0.8, 0.2\n",
        "input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "\n",
        "# Cargar proyección UMAP y clusters\n",
        "database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "# Reducir dimensiones con UMAP\n",
        "import umap\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "projection = reducer.fit_transform(database_num)\n",
        "\n",
        "# Crear DataFrame para análisis\n",
        "df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "# Agrupar clusters usando KMeans sobre la proyección UMAP\n",
        "kmeans_vis = KMeans(n_clusters=4, random_state=42)\n",
        "df_plot[\"group\"] = kmeans_vis.fit_predict(df_plot[[\"x\", \"y\"]])\n",
        "\n",
        "# Listar clusters por grupo\n",
        "group_to_clusters = df_plot.groupby(\"group\")[\"cluster\"].unique().to_dict()\n",
        "group_to_clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeoCardKn3aX"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def visualizar_clusters_umap(region=\"america\", a=0.8, b=0.2):\n",
        "    input_dir = Path(\"res\") / region / \"todos_los_anios\"\n",
        "    output_dir = Path(\"analisis\") / \"todos_los_anios\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        print(\"📊 Generando proyección UMAP…\")\n",
        "        database_num = pd.read_csv(input_dir / \"base_numerica.csv\")\n",
        "        df_clusters = pd.read_csv(input_dir / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "\n",
        "        reducer = umap.UMAP(random_state=42)\n",
        "        projection = reducer.fit_transform(database_num)\n",
        "\n",
        "        df_plot = pd.DataFrame(projection, columns=[\"x\", \"y\"])\n",
        "        df_plot[\"cluster\"] = df_clusters[\"cluster\"].astype(str)\n",
        "\n",
        "        plt.figure(figsize=(12, 8))  # gráfico más grande\n",
        "        sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"cluster\", palette=\"tab10\", s=10, alpha=0.7)\n",
        "\n",
        "        # Ajustes para expandir visualmente el área\n",
        "        margin = 2\n",
        "        plt.xlim(df_plot[\"x\"].min() - margin, df_plot[\"x\"].max() + margin)\n",
        "        plt.ylim(df_plot[\"y\"].min() - margin, df_plot[\"y\"].max() + margin)\n",
        "\n",
        "        plt.title(f\"Visualización de clusters con UMAP (a={a}, b={b})\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f\"umap_clusters_{a:.1f}_{b:.1f}.png\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✅ Gráfico de clusters generado y guardado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error generando gráfico UMAP: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLOuuHran4wQ"
      },
      "outputs": [],
      "source": [
        "visualizar_clusters_umap()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw1rlCQA3W05"
      },
      "outputs": [],
      "source": [
        "# Reimportar librerías tras reinicio del entorno\n",
        "import pandas as pd\n",
        "import pickle as pick\n",
        "from pathlib import Path\n",
        "\n",
        "# Cargar paths\n",
        "region = \"america\"\n",
        "a, b = 0.8, 0.2\n",
        "base_path = Path(\"res\") / region / \"todos_los_anios\"\n",
        "\n",
        "# Cargar archivos necesarios nuevamente\n",
        "with open(base_path / \"list_trips.pkl\", \"rb\") as f:\n",
        "    list_trips = pick.load(f)\n",
        "\n",
        "df_clusters = pd.read_csv(base_path / f\"{a:.1f}_{b:.1f}_clusters.csv\")\n",
        "df_original = pd.read_excel(\"/content/drive/MyDrive/proyecto_ingeneria/df.xlsx\", engine=\"openpyxl\", dtype=str)\n",
        "df_original[\"date_review\"] = pd.to_datetime(df_original[\"date_review\"], errors=\"coerce\")\n",
        "\n",
        "# Crear DataFrame de estancias\n",
        "records = []\n",
        "for trip_id, (locations, season, duration, user) in list_trips.items():\n",
        "    user_reviews = df_original[(df_original[\"memberID\"] == user) & (df_original[\"id\"].isin(locations))]\n",
        "    for _, row in user_reviews.iterrows():\n",
        "        records.append({\n",
        "            \"trip_id\": trip_id,\n",
        "            \"memberID\": row[\"memberID\"],\n",
        "            \"country\": row[\"country\"],\n",
        "            \"reviewed_location\": row[\"reviewed_location\"],\n",
        "            \"id\": row[\"id\"],\n",
        "            \"cluster\": df_clusters.loc[trip_id, \"cluster\"]\n",
        "        })\n",
        "\n",
        "df_stays = pd.DataFrame(records)\n",
        "\n",
        "# Guardar Excel\n",
        "output_path = base_path / f\"estancias_clusterizadas.xlsx\"\n",
        "df_stays.to_excel(output_path, index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
